{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submissions/starting_kit/image_classifier.py\n"
     ]
    }
   ],
   "source": [
    "%%file submissions/starting_kit/image_classifier.py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from rampwf.workflows.image_classifier import get_nb_minibatches\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "class ImageClassifier(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.batch_size = 5\n",
    "        self.img_width, self.img_height = 32, 32\n",
    "        self.model = Sequential()\n",
    "        self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        \n",
    "        # Forme de l'input en fonction du backend\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            self.input_shape = (3, self.img_width, self.img_height)\n",
    "        else:\n",
    "            self.input_shape = (self.img_width, self.img_height, 3)\n",
    "\n",
    "        self.model.add(Conv2D(32, (3, 3), input_shape=self.input_shape))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        self.model.add(Conv2D(64, (3, 3)))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        self.model.add(Conv2D(64, (3, 3)))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(64))\n",
    "        self.model.add(Activation('relu'))\n",
    "        self.model.add(Dropout(0.5))\n",
    "        \n",
    "        # Compute the probabilities of the ten classes\n",
    "        self.model.add(Dense(10)) \n",
    "        self.model.add(Activation('softmax'))\n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    def _transform(self, x):\n",
    "        x = resize(x, (self.img_width, self.img_height), preserve_range=True, anti_aliasing=False)\n",
    "        # bringing input between 0 and 1\n",
    "        x = x / 255.\n",
    "        return x\n",
    "\n",
    "    def _build_train_generator(self, img_loader, indices, batch_size,\n",
    "                               shuffle=False):\n",
    "        indices = indices.copy()\n",
    "        nb = len(indices)\n",
    "        X = np.zeros((batch_size, self.img_width, self.img_height, 3))\n",
    "        Y = np.zeros((batch_size, 10))\n",
    "        while True:\n",
    "            if shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "            for start in range(0, nb, batch_size):\n",
    "                stop = min(start + batch_size, nb)\n",
    "                # load the next minibatch in memory.\n",
    "                # The size of the minibatch is (stop - start),\n",
    "                # which is `batch_size` for the all except the last\n",
    "                # minibatch, which can either be `batch_size` if\n",
    "                # `nb` is a multiple of `batch_size`, or `nb % batch_size`.\n",
    "                bs = stop - start\n",
    "                Y[:] = 0\n",
    "                for i, img_index in enumerate(indices[start:stop]):\n",
    "                    x, y = img_loader.load(img_index)\n",
    "                    print(x.shape)\n",
    "                    if (x.shape)==(1163, 1600, 3): #(1536, 2048, 3):\n",
    "                        plt.imshow(x)\n",
    "                     # TODO TEMP\n",
    "                    if len(x.shape)!=3 or x.shape[2]!=3 or x.shape[1]==1200:\n",
    "                        print('passed')\n",
    "                        Y[i, 0] = 1\n",
    "                        continue\n",
    "                    x = self._transform(x)\n",
    "                    X[i] = x\n",
    "                    Y[i, y] = 1\n",
    "                yield X[:bs], Y[:bs]\n",
    "\n",
    "    def _build_test_generator(self, img_loader, batch_size):\n",
    "        nb = len(img_loader)\n",
    "        X = np.zeros((batch_size, self.img_width, self.img_height, 3))\n",
    "        while True:\n",
    "            for start in range(0, nb, batch_size):\n",
    "                stop = min(start + batch_size, nb)\n",
    "                # load the next minibatch in memory.\n",
    "                # The size of the minibatch is (stop - start),\n",
    "                # which is `batch_size` for the all except the last\n",
    "                # minibatch, which can either be `batch_size` if\n",
    "                # `nb` is a multiple of `batch_size`, or `nb % batch_size`.\n",
    "                bs = stop - start\n",
    "                for i, img_index in enumerate(range(start, stop)):\n",
    "                    x = img_loader.load(img_index)\n",
    "                    x = self._transform(x)\n",
    "                    X[i] = x\n",
    "                yield X[:bs]\n",
    "\n",
    "    def fit(self, img_loader):\n",
    "        np.random.seed(24)\n",
    "        nb = len(img_loader)\n",
    "        nb_train = int(nb * 0.9)\n",
    "        nb_valid = nb - nb_train\n",
    "        indices = np.arange(nb)\n",
    "        np.random.shuffle(indices)\n",
    "        ind_train = indices[0: nb_train]\n",
    "        ind_valid = indices[nb_train:]\n",
    "\n",
    "        gen_train = self._build_train_generator(\n",
    "            img_loader,\n",
    "            indices=ind_train,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "        gen_valid = self._build_train_generator(\n",
    "            img_loader,\n",
    "            indices=ind_valid,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "        self.model.fit_generator(\n",
    "            gen_train,\n",
    "            steps_per_epoch=get_nb_minibatches(nb_train, self.batch_size),\n",
    "            epochs=1,\n",
    "            max_queue_size=16,\n",
    "            workers=1,\n",
    "            use_multiprocessing=True,\n",
    "            validation_data=gen_valid,\n",
    "            validation_steps=get_nb_minibatches(nb_valid, self.batch_size),\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def predict_proba(self, img_loader):\n",
    "        nb_test = len(img_loader)\n",
    "        gen_test = self._build_test_generator(img_loader, self.batch_size)\n",
    "        return self.model.predict_generator(\n",
    "            gen_test,\n",
    "            steps=get_nb_minibatches(nb_test, self.batch_size),\n",
    "            max_queue_size=16,\n",
    "            workers=1,\n",
    "            use_multiprocessing=True,\n",
    "            verbose=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;178m\u001b[1mTesting Fruits and vegetables classification (10 classes)\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading train and test files from ./data ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mReading cv ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mTraining submissions/starting_kit ...\u001b[0m\n",
      "\u001b[38;5;178m\u001b[1mCV fold 0\u001b[0m\n",
      "Using TensorFlow backend.\n",
      "Epoch 1/1\n",
      "(2100, 650, 3)\n",
      "/home/alexandre/Projects/master/datacamp/collab/clbenv/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "(1536, 2048, 3)\n",
      "/home/alexandre/Projects/master/datacamp/collab/clbenv/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "(1024, 768, 3)\n",
      "(278, 278, 3)\n",
      "(750, 1000, 3)\n",
      "(675, 948, 4)\n",
      "passed\n",
      "(533, 800, 3)\n",
      "(1365, 2048, 3)\n",
      "(1226, 800, 3)\n",
      "(2215, 3478, 3)\n",
      "(844, 1500, 3)\n",
      "(1125, 1688, 3)\n",
      "(610, 570, 3)\n",
      "(1198, 1200, 3)\n",
      "passed\n",
      "2019-01-30 20:04:05.786122: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "(680, 1024, 3)\n",
      "(700, 700, 3)\n",
      "(1420, 2136, 3)\n",
      "(683, 1024, 3)\n",
      "(1936, 2592, 3)\n",
      "(1513, 2048, 3)\n",
      "(1536, 1536, 3)\n",
      "2019-01-30 20:04:06.673224: W tensorflow/core/framework/allocator.cc:122] Allocation of 19663488 exceeds 10% of system memory.\n",
      "2019-01-30 20:04:06.673224: W tensorflow/core/framework/allocator.cc:122] Allocation of 19663488 exceeds 10% of system memory.\n",
      "  1/859 [..............................] - ETA: 37:42 - loss: 2.3500 - acc: 0.6000(307, 500, 3)\n",
      "(1361, 2048, 3)\n",
      "(2304, 3072, 3)\n",
      "(1024, 1540, 3)\n",
      "2019-01-30 20:04:07.358121: W tensorflow/core/framework/allocator.cc:122] Allocation of 19663488 exceeds 10% of system memory.\n",
      "2019-01-30 20:04:07.358269: W tensorflow/core/framework/allocator.cc:122] Allocation of 19663488 exceeds 10% of system memory.\n",
      "  2/859 [..............................] - ETA: 23:37 - loss: 2.3735 - acc: 0.3000(1200, 1600, 3)\n",
      "(1200, 1600, 3)\n",
      "(1731, 2048, 3)\n",
      "(2848, 4272, 3)\n",
      "(235, 350, 3)\n",
      "(2162, 2882, 3)\n",
      "2019-01-30 20:04:08.586748: W tensorflow/core/framework/allocator.cc:122] Allocation of 19663488 exceeds 10% of system memory.\n",
      "  3/859 [..............................] - ETA: 21:38 - loss: 2.2912 - acc: 0.3333(1200, 1200, 3)\n",
      "passed\n",
      "(334, 500, 3)\n",
      "(960, 1280, 3)\n",
      "(1024, 995, 3)\n",
      "(540, 310, 4)\n",
      "passed\n",
      "(1274, 2048, 3)\n",
      "(1936, 2592, 3)\n",
      "(375, 500, 3)\n",
      "(2002, 3000, 3)\n",
      "(600, 800, 3)\n",
      "(3216, 2136, 3)\n",
      "  4/859 [..............................] - ETA: 20:09 - loss: 2.3696 - acc: 0.2500(1177, 1772, 3)\n",
      "(1024, 611, 3)\n",
      "(632, 800, 3)\n",
      "(1280, 1280, 3)\n",
      "(1418, 1061, 3)\n",
      "(2048, 1365, 3)\n",
      "(3872, 2592, 3)\n",
      "(2848, 4272, 3)\n",
      "  5/859 [..............................] - ETA: 21:13 - loss: 2.3758 - acc: 0.2000(590, 391, 3)\n",
      "(1024, 683, 3)\n",
      "(720, 720, 3)\n",
      "(567, 378, 3)\n",
      "(559, 700, 3)\n",
      "(1050, 717, 3)\n",
      "(765, 1024, 3)\n",
      "  6/859 [..............................] - ETA: 18:47 - loss: 2.3800 - acc: 0.1667(1024, 1024, 3)\n",
      "(240, 370, 3)\n",
      "(683, 1024, 3)\n",
      "(1167, 1600, 3)\n",
      "(2756, 3846, 3)\n",
      "(3909, 5857, 3)\n",
      "(1640, 2112, 3)\n",
      "(803, 1200, 3)\n",
      "passed\n",
      "(2448, 3264, 3)\n",
      "  7/859 [..............................] - ETA: 20:45 - loss: 2.3505 - acc: 0.1429(2138, 2884, 3)\n",
      "(1698, 2408, 3)\n",
      "(683, 1024, 3)\n",
      "(1200, 1200, 3)\n",
      "passed\n",
      "(480, 640, 3)\n",
      "(1741, 1920, 3)\n",
      "(1536, 2048, 3)\n",
      "(768, 774, 3)\n",
      "(2144, 1424, 3)\n",
      "(1944, 2592, 3)\n",
      "(402, 600, 3)\n",
      "  8/859 [..............................] - ETA: 20:29 - loss: 2.3524 - acc: 0.1250(1394, 2270, 3)\n",
      "(3336, 5119, 3)\n",
      "(4608, 3456, 3)\n",
      "(2304, 2840, 3)\n",
      "(380, 500, 3)\n",
      "(768, 1024, 3)\n",
      "  9/859 [..............................] - ETA: 21:39 - loss: 2.3524 - acc: 0.1333(666, 1000, 3)\n",
      "(1024, 683, 3)\n",
      "(674, 1199, 3)\n",
      "(1193, 1200, 3)\n",
      "passed\n",
      "(1200, 1600, 3)\n",
      "(1600, 1200, 3)\n",
      "passed\n",
      "(1936, 1936, 3)\n",
      "(1936, 2592, 3)\n",
      "(1024, 768, 3)\n",
      "(180, 240, 3)\n",
      " 10/859 [..............................] - ETA: 20:37 - loss: 2.3401 - acc: 0.1400(361, 642, 3)\n",
      "(829, 1024, 3)\n",
      "(392, 587, 3)\n",
      "(1024, 679, 3)\n",
      "(768, 1024, 3)\n",
      "(310, 232, 3)\n",
      " 11/859 [..............................] - ETA: 19:07 - loss: 2.3324 - acc: 0.1455(1200, 1200, 3)\n",
      "passed\n",
      "(1410, 2126, 3)\n",
      "(640, 480, 3)\n",
      "(850, 592, 3)\n",
      "(689, 1023, 3)\n",
      "(380, 322, 3)\n",
      " 12/859 [..............................] - ETA: 18:17 - loss: 2.3278 - acc: 0.1500(694, 1024, 3)\n",
      "(3240, 4320, 3)\n",
      "(2490, 3870, 3)\n",
      "(600, 800, 3)\n",
      "(267, 400, 3)\n",
      "(3008, 2000, 3)\n",
      "(1600, 1600, 3)\n",
      "(302, 300, 3)\n",
      " 13/859 [..............................] - ETA: 18:28 - loss: 2.3409 - acc: 0.1385(567, 847, 3)\n",
      "(685, 1024, 3)\n",
      "(1600, 1200, 3)\n",
      "passed\n",
      "(300, 202, 3)\n",
      "(1177, 1772, 3)\n",
      "(800, 1200, 3)\n",
      "passed\n",
      "(1704, 2272, 3)\n",
      " 14/859 [..............................] - ETA: 17:48 - loss: 2.3369 - acc: 0.1286(2592, 3456, 3)\n",
      "(2720, 4194, 3)\n",
      "(2088, 2061, 3)\n",
      "(1000, 1000, 3)\n",
      "(1000, 1200, 3)\n",
      "passed\n",
      "(768, 511, 3)\n",
      "(624, 832, 3)\n",
      "(646, 810, 3)\n",
      "(1024, 771, 3)\n",
      "(1536, 2048, 3)\n",
      "(1024, 794, 3)\n",
      "(768, 1024, 3)\n",
      "(681, 1024, 3)\n",
      "(376, 376, 3)\n",
      "(2272, 1704, 3)\n",
      " 15/859 [..............................] - ETA: 18:16 - loss: 2.3331 - acc: 0.1333(1600, 1200, 3)\n",
      "passed\n",
      "(480, 640, 3)\n",
      "(768, 1024, 3)\n",
      "(1536, 2048, 3)\n",
      "(340, 758, 3)\n",
      "(1600, 1200, 3)\n",
      "passed\n",
      "(244, 244, 3)\n",
      "(2988, 5312, 3)\n",
      "(3072, 4608, 3)\n",
      "(829, 1204, 3)\n",
      "(2448, 3264, 3)\n",
      "(800, 800, 3)\n",
      "(782, 1024, 3)\n",
      "(1049, 700, 3)\n",
      " 16/859 [..............................] - ETA: 19:59 - loss: 2.3244 - acc: 0.1500(683, 1024, 4)\n",
      "passed\n",
      "(800, 1200, 3)\n",
      "passed\n",
      "(250, 385, 3)\n",
      "(600, 600, 3)\n",
      "(960, 1280, 3)\n",
      "(2448, 3264, 3)\n",
      "(2666, 4000, 3)\n",
      "(1867, 2800, 3)\n",
      "(349, 620, 3)\n",
      "(1200, 1600, 3)\n",
      "(1024, 953, 3)\n",
      "(1000, 1000, 3)\n",
      " 17/859 [..............................] - ETA: 20:14 - loss: 2.3230 - acc: 0.1647(800, 800, 3)\n",
      "(1000, 1000, 3)\n",
      "(749, 1000, 4)\n",
      "passed\n",
      "(1944, 2265, 3)\n",
      "(1200, 1800, 3)\n",
      "(1600, 1143, 3)\n",
      "(4272, 2848, 3)\n",
      "(720, 1280, 3)\n",
      "(713, 1042, 4)\n",
      "passed\n",
      " 18/859 [..............................] - ETA: 20:07 - loss: 2.3099 - acc: 0.1667(1920, 1280, 3)\n",
      "(1200, 1600, 3)\n",
      "(750, 502, 3)\n",
      "(575, 450, 3)\n",
      "(1370, 2048, 3)\n",
      " 19/859 [..............................] - ETA: 19:30 - loss: 2.3293 - acc: 0.1579(3456, 5184, 3)\n",
      "(2484, 3440, 3)\n",
      "(1200, 1200, 3)\n",
      "passed\n",
      "(874, 1200, 4)\n",
      "passed\n",
      "(2048, 2048, 3)\n",
      "(1000, 1600, 3)\n",
      "(1280, 851, 3)\n",
      " 20/859 [..............................] - ETA: 19:26 - loss: 2.3218 - acc: 0.1700(2304, 3456, 3)\n",
      "(1168, 1300, 3)\n",
      "(3172, 4500, 3)\n",
      "(2490, 3600, 3)\n",
      "(600, 800, 3)\n",
      "(512, 512, 3)\n",
      "(425, 850, 3)\n",
      "(956, 1300, 3)\n",
      " 21/859 [..............................] - ETA: 19:52 - loss: 2.3212 - acc: 0.1714(3072, 4608, 3)\n",
      "(630, 1200, 3)\n",
      "passed\n",
      "(1067, 1600, 3)\n",
      "(2332, 1666, 3)\n",
      "(2592, 1952, 3)\n",
      " 22/859 [..............................] - ETA: 20:29 - loss: 2.3122 - acc: 0.1727(500, 334, 3)\n",
      "(378, 378, 3)\n",
      "(2592, 3872, 3)\n",
      "(1920, 2560, 3)\n",
      "(400, 500, 3)\n",
      " 23/859 [..............................] - ETA: 20:17 - loss: 2.3001 - acc: 0.1739(1867, 2800, 3)\n",
      "(600, 480, 3)\n",
      "(2592, 3888, 3)\n",
      "(1153, 2048, 3)\n",
      "(505, 640, 3)\n",
      " 24/859 [..............................] - ETA: 20:16 - loss: 2.3062 - acc: 0.1667(3456, 5184, 3)\n",
      "(280, 547, 3)\n",
      "(768, 1024, 3)\n",
      "(1054, 1200, 3)\n",
      "passed\n",
      "(2000, 2000, 3)\n",
      " 25/859 [..............................] - ETA: 20:37 - loss: 2.3064 - acc: 0.1680(720, 720, 3)\n",
      "(768, 1024, 3)\n",
      "(250, 250, 3)\n",
      "(300, 300, 4)\n",
      "passed\n",
      "(1499, 2048, 3)\n",
      " 26/859 [..............................] - ETA: 20:03 - loss: 2.3021 - acc: 0.1615(978, 810, 3)\n",
      "(2848, 4288, 3)\n",
      "(282, 425, 3)\n",
      "(1704, 2272, 3)\n",
      "(1230, 820, 3)\n",
      " 27/859 [..............................] - ETA: 19:57 - loss: 2.3011 - acc: 0.1556(710, 474, 3)\n",
      "(1496, 2256, 3)\n",
      "(1200, 1200, 3)\n",
      "passed\n",
      "(2048, 1473, 3)\n",
      "(640, 800, 3)\n",
      " 28/859 [..............................] - ETA: 19:35 - loss: 2.2963 - acc: 0.1571(1356, 2048, 3)\n",
      "(2304, 3456, 3)\n",
      "(600, 800, 3)\n",
      "(300, 400, 3)\n",
      "(803, 1200, 3)\n",
      "passed\n",
      " 29/859 [>.............................] - ETA: 19:25 - loss: 2.2821 - acc: 0.1655(1500, 1500, 3)\n",
      "(1024, 685, 3)\n",
      "(985, 1500, 3)\n",
      "(458, 640, 3)\n",
      "(1200, 1600, 3)\n",
      " 30/859 [>.............................] - ETA: 19:03 - loss: 2.2771 - acc: 0.1667(1067, 1600, 3)\n",
      "(480, 640, 3)\n",
      "(344, 500, 3)\n",
      "(1000, 1000, 3)\n",
      "(683, 1024, 3)\n",
      " 31/859 [>.............................] - ETA: 18:36 - loss: 2.2890 - acc: 0.1613(1024, 683, 3)\n",
      "(336, 336, 3)\n",
      "(2304, 3072, 3)\n",
      "(334, 500, 3)\n",
      "(1351, 1802, 3)\n",
      " 32/859 [>.............................] - ETA: 18:21 - loss: 2.2828 - acc: 0.1688(2736, 3648, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 859, 3)\n",
      "(685, 1024, 3)\n",
      "(2048, 1365, 3)\n",
      "(2000, 3008, 3)\n",
      " 33/859 [>.............................] - ETA: 18:23 - loss: 2.2875 - acc: 0.1636(2304, 3072, 3)\n",
      "(265, 320, 3)\n",
      "(443, 640, 3)\n",
      "(563, 612, 3)\n",
      "(667, 1000, 3)\n",
      " 34/859 [>.............................] - ETA: 18:05 - loss: 2.2957 - acc: 0.1588(1000, 1000, 3)\n",
      "(823, 1024, 3)\n",
      "(1480, 4260, 3)\n",
      "(320, 450, 3)\n",
      "(1536, 2048, 3)\n",
      " 35/859 [>.............................] - ETA: 17:57 - loss: 2.2943 - acc: 0.1600(1200, 1600, 3)\n",
      "(4288, 2848, 3)\n",
      "(878, 1500, 4)\n",
      "passed\n",
      "(1600, 1201, 3)\n",
      "(363, 600, 4)\n",
      "passed\n",
      " 36/859 [>.............................] - ETA: 18:02 - loss: 2.2880 - acc: 0.1667(3648, 2736, 3)\n",
      "(3346, 2530, 3)\n",
      "(1423, 2048, 3)\n",
      "(467, 700, 3)\n",
      "(580, 600, 4)\n",
      "passed\n",
      " 37/859 [>.............................] - ETA: 18:07 - loss: 2.2866 - acc: 0.1676(683, 1024, 3)\n",
      "(960, 1280, 3)\n",
      "(360, 460, 3)\n",
      "(800, 800, 3)\n",
      "(2220, 1944, 3)\n",
      "(255, 279, 3)\n",
      " 38/859 [>.............................] - ETA: 17:52 - loss: 2.2974 - acc: 0.1632(768, 1024, 3)\n",
      "(335, 500, 3)\n",
      "(1024, 681, 3)\n",
      "(566, 864, 3)\n",
      " 39/859 [>.............................] - ETA: 17:28 - loss: 2.2987 - acc: 0.1641(3008, 2000, 3)\n",
      "(680, 1024, 3)\n",
      "(1233, 1537, 3)\n",
      "(375, 500, 3)\n",
      "(3110, 2021, 3)\n",
      " 40/859 [>.............................] - ETA: 17:25 - loss: 2.2988 - acc: 0.1600(1200, 1200, 3)\n",
      "passed\n",
      "(1066, 1600, 3)\n",
      "(701, 1024, 3)\n",
      "(3312, 4416, 3)\n",
      "(2419, 2601, 3)\n",
      " 41/859 [>.............................] - ETA: 17:34 - loss: 2.2984 - acc: 0.1610(480, 640, 3)\n",
      "(2448, 3264, 3)\n",
      "(1000, 1000, 3)\n",
      "(1200, 1200, 3)\n",
      "passed\n",
      "(1415, 2122, 3)\n",
      " 42/859 [>.............................] - ETA: 17:28 - loss: 2.2972 - acc: 0.1619(1200, 1043, 3)\n",
      "(360, 360, 3)\n",
      "(2988, 2000, 3)\n",
      "(2048, 1896, 3)\n",
      "(532, 800, 3)\n",
      " 43/859 [>.............................] - ETA: 17:19 - loss: 2.2949 - acc: 0.1674(1152, 2048, 3)\n",
      "(500, 375, 3)\n",
      "(797, 1200, 3)\n",
      "passed\n",
      "(611, 689, 3)\n",
      "(338, 600, 3)\n",
      " 44/859 [>.............................] - ETA: 16:59 - loss: 2.2946 - acc: 0.1682(1200, 1920, 3)\n",
      "(320, 320, 3)\n",
      "(1024, 683, 3)\n",
      "(591, 1200, 3)\n",
      "passed\n",
      "(3735, 2592, 3)\n",
      " 45/859 [>.............................] - ETA: 16:53 - loss: 2.2939 - acc: 0.1689(1027, 782, 3)\n",
      "(1668, 2500, 3)\n",
      "(664, 1024, 3)\n",
      "(426, 640, 3)\n",
      "(358, 590, 3)\n",
      " 46/859 [>.............................] - ETA: 16:37 - loss: 2.2931 - acc: 0.1696(2048, 1953, 3)\n",
      "(450, 450, 3)\n",
      "(1024, 750, 3)\n",
      "(1198, 1200, 3)\n",
      "passed\n",
      "(293, 370, 3)\n",
      " 47/859 [>.............................] - ETA: 16:24 - loss: 2.2971 - acc: 0.1702(548, 1024, 3)\n",
      "(1508, 2048, 3)\n",
      "(4032, 3024, 3)\n",
      "(1024, 768, 3)\n",
      "(682, 1024, 3)\n",
      " 48/859 [>.............................] - ETA: 16:24 - loss: 2.2977 - acc: 0.1667(2000, 1500, 3)\n",
      "(300, 300, 3)\n",
      "(600, 800, 3)\n",
      "(333, 500, 3)\n",
      "(390, 504, 3)\n",
      " 49/859 [>.............................] - ETA: 16:08 - loss: 2.3004 - acc: 0.1633(5184, 3456, 3)\n",
      "(900, 1024, 3)\n",
      "(612, 612, 3)\n",
      "(3456, 5184, 3)\n",
      "(768, 1024, 3)\n",
      " 50/859 [>.............................] - ETA: 16:37 - loss: 2.3014 - acc: 0.1640(600, 800, 3)\n",
      "(721, 1065, 3)\n",
      "(462, 600, 3)\n",
      "(1365, 2048, 3)\n",
      "(847, 1280, 3)\n",
      " 51/859 [>.............................] - ETA: 16:23 - loss: 2.3015 - acc: 0.1686(3888, 2592, 3)\n",
      "(600, 900, 3)\n",
      "(720, 1280, 3)\n",
      "(216, 645, 3)\n",
      "(309, 550, 3)\n",
      "(530, 538, 4)\n",
      "passed\n",
      " 52/859 [>.............................] - ETA: 16:20 - loss: 2.2999 - acc: 0.1692(2298, 3456, 3)\n",
      "(1024, 1024, 3)\n",
      "(532, 800, 3)\n",
      "(3648, 2736, 3)\n",
      " 53/859 [>.............................] - ETA: 16:25 - loss: 2.2994 - acc: 0.1698(500, 333, 3)\n",
      "(513, 640, 3)\n",
      "(680, 1024, 3)\n",
      "(3456, 5184, 3)\n",
      "(600, 800, 3)\n",
      " 54/859 [>.............................] - ETA: 16:28 - loss: 2.2996 - acc: 0.1667(533, 800, 3)\n",
      "(1200, 1600, 3)\n",
      "(1365, 2048, 3)\n",
      "(1077, 1616, 3)\n",
      "(561, 563, 3)\n",
      " 55/859 [>.............................] - ETA: 16:18 - loss: 2.3013 - acc: 0.1636(2269, 3416, 3)\n",
      "(809, 1024, 3)\n",
      "(1154, 1646, 3)\n",
      "(1704, 2272, 3)\n",
      "(355, 355, 3)\n",
      " 56/859 [>.............................] - ETA: 16:15 - loss: 2.3004 - acc: 0.1643(900, 600, 3)\n",
      "(2, 3648, 2736, 3)\n",
      "passed\n",
      "(1113, 1300, 3)\n",
      "(682, 1024, 3)\n",
      "(856, 1181, 3)\n",
      " 57/859 [>.............................] - ETA: 16:08 - loss: 2.3009 - acc: 0.1649(375, 500, 3)\n",
      "(570, 857, 3)\n",
      "(1200, 1600, 3)\n",
      "(768, 1024, 3)\n",
      "(2248, 4000, 3)\n",
      " 58/859 [=>............................] - ETA: 16:04 - loss: 2.3005 - acc: 0.1621(844, 1024, 3)\n",
      "(687, 1024, 3)\n",
      "(2000, 3000, 3)\n",
      "(800, 800, 3)\n",
      "(781, 1170, 3)\n",
      " 59/859 [=>............................] - ETA: 15:56 - loss: 2.3004 - acc: 0.1593(2048, 2048, 3)\n",
      "(2448, 3264, 3)\n",
      "(638, 850, 3)\n",
      "(800, 800, 3)\n",
      "(1536, 2048, 3)\n",
      "(300, 450, 3)\n",
      " 60/859 [=>............................] - ETA: 15:57 - loss: 2.3005 - acc: 0.1567(858, 860, 3)\n",
      "(375, 500, 3)\n",
      "(2848, 4272, 3)\n",
      "(800, 1211, 3)\n",
      " 61/859 [=>............................] - ETA: 15:53 - loss: 2.2993 - acc: 0.1541(1561, 2448, 3)\n",
      "(1200, 1200, 3)\n",
      "passed\n"
     ]
    }
   ],
   "source": [
    "!ramp_test_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
